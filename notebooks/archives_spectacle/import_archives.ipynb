{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For one organism and one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organism_id</th>\n",
       "      <th>year</th>\n",
       "      <th>performance</th>\n",
       "      <th>performanceId</th>\n",
       "      <th>author</th>\n",
       "      <th>authordId</th>\n",
       "      <th>label</th>\n",
       "      <th>period</th>\n",
       "      <th>occurency</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\nBiennale de Danse en Lorraine\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>Shadoz</td>\n",
       "      <td>52149</td>\n",
       "      <td>Isabelle Renaud</td>\n",
       "      <td>109922</td>\n",
       "      <td>\\nShadoz  chorégraphie Isabelle Renaud\\n</td>\n",
       "      <td>\\n09/10 → 10/10\\n</td>\n",
       "      <td>[1 rep. + 2 scol.]</td>\n",
       "      <td>\\n (Salle de l'Esplanade)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>An Evening with Trisha</td>\n",
       "      <td>50265</td>\n",
       "      <td>Trisha Brown</td>\n",
       "      <td>9113</td>\n",
       "      <td>\\nAn Evening with Trisha  chorégraphie Trisha ...</td>\n",
       "      <td>\\n18/10\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n (Grande salle)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>Atem</td>\n",
       "      <td>43870</td>\n",
       "      <td>Josef Nadj</td>\n",
       "      <td>269</td>\n",
       "      <td>\\nAtem  chorégraphie Josef Nadj\\n</td>\n",
       "      <td>\\n20/11 → 24/11\\n</td>\n",
       "      <td>[5 rep.]</td>\n",
       "      <td>\\n (Studio du Gouverneur)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>Cantatas</td>\n",
       "      <td>50263</td>\n",
       "      <td>Raimund Hoghe</td>\n",
       "      <td>6500</td>\n",
       "      <td>\\nCantatas  chorégraphie Raimund Hoghe concept...</td>\n",
       "      <td>\\n16/12\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n (Grande salle)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>(M)imosa</td>\n",
       "      <td>33746</td>\n",
       "      <td>Cecilia Bengolea</td>\n",
       "      <td>18144</td>\n",
       "      <td>\\n(M)imosa  conception Cecilia Bengolea…\\n\\n  ...</td>\n",
       "      <td>\\n31/01 → 01/02\\n</td>\n",
       "      <td>[2 rep.]</td>\n",
       "      <td>\\n (Studio du Gouverneur)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>Baron Samedi</td>\n",
       "      <td>37881</td>\n",
       "      <td>Alain Buffard</td>\n",
       "      <td>16828</td>\n",
       "      <td>\\nBaron Samedi  conception Alain Buffard\\n</td>\n",
       "      <td>\\n13/02\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n (Grande salle)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>Le Tsar Saltan</td>\n",
       "      <td>52148</td>\n",
       "      <td>Nikolaï Rimski-Korsakov</td>\n",
       "      <td>96812</td>\n",
       "      <td>\\nLe Tsar Saltan musique Nikolaï Rimski-Korsak...</td>\n",
       "      <td>\\n06/04\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>Chez Joséphine</td>\n",
       "      <td>51316</td>\n",
       "      <td>Raphaëlle Delaunay</td>\n",
       "      <td>7811</td>\n",
       "      <td>\\nChez Joséphine  chorégraphie Raphaëlle Delau...</td>\n",
       "      <td>\\n16/04\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n (Grande salle)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>Rotkäppchen</td>\n",
       "      <td>39082</td>\n",
       "      <td>Sylvain Huc</td>\n",
       "      <td>34267</td>\n",
       "      <td>\\nRotkäppchen  chorégraphie Sylvain Huc\\n</td>\n",
       "      <td>\\n23/04\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n”  (Grande salle)\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\nEast Block Party\\n</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>Now the field is open</td>\n",
       "      <td>42160</td>\n",
       "      <td>Hooman Sharifi</td>\n",
       "      <td>45775</td>\n",
       "      <td>\\nNow the field is open  chorégraphie Hooman S...</td>\n",
       "      <td>\\n15/05\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n (Grande salle)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>Promenade obligatoire</td>\n",
       "      <td>37847</td>\n",
       "      <td>Anne Nguyen</td>\n",
       "      <td>42974</td>\n",
       "      <td>\\nPromenade obligatoire  chorégraphie Anne Ngu...</td>\n",
       "      <td>\\n17/05\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n”  (Grande salle)\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>439</td>\n",
       "      <td>2013</td>\n",
       "      <td>États des lieux</td>\n",
       "      <td>52150</td>\n",
       "      <td>Aurélie Gandit</td>\n",
       "      <td>57989</td>\n",
       "      <td>\\nÉtats des lieux  chorégraphie Aurélie Gandit\\n</td>\n",
       "      <td>\\n14/06 → 15/06\\n</td>\n",
       "      <td>[5 rep.]</td>\n",
       "      <td>\\n (Grande salle)\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   organism_id  year             performance performanceId  \\\n",
       "0          439  2013                                         \n",
       "1          439  2013                  Shadoz         52149   \n",
       "2          439  2013  An Evening with Trisha         50265   \n",
       "3          439  2013                    Atem         43870   \n",
       "4          439  2013                Cantatas         50263   \n",
       "5          439  2013                (M)imosa         33746   \n",
       "6          439  2013            Baron Samedi         37881   \n",
       "7          439  2013          Le Tsar Saltan         52148   \n",
       "8          439  2013          Chez Joséphine         51316   \n",
       "9          439  2013             Rotkäppchen         39082   \n",
       "10         439  2013                                         \n",
       "11         439  2013                                         \n",
       "12         439  2013   Now the field is open         42160   \n",
       "13         439  2013   Promenade obligatoire         37847   \n",
       "14         439  2013         États des lieux         52150   \n",
       "\n",
       "                     author authordId  \\\n",
       "0                                       \n",
       "1           Isabelle Renaud    109922   \n",
       "2              Trisha Brown      9113   \n",
       "3                Josef Nadj       269   \n",
       "4             Raimund Hoghe      6500   \n",
       "5          Cecilia Bengolea     18144   \n",
       "6             Alain Buffard     16828   \n",
       "7   Nikolaï Rimski-Korsakov     96812   \n",
       "8        Raphaëlle Delaunay      7811   \n",
       "9               Sylvain Huc     34267   \n",
       "10                                      \n",
       "11                                      \n",
       "12           Hooman Sharifi     45775   \n",
       "13              Anne Nguyen     42974   \n",
       "14           Aurélie Gandit     57989   \n",
       "\n",
       "                                                label             period  \\\n",
       "0                   \\nBiennale de Danse en Lorraine\\n                      \n",
       "1            \\nShadoz  chorégraphie Isabelle Renaud\\n  \\n09/10 → 10/10\\n   \n",
       "2   \\nAn Evening with Trisha  chorégraphie Trisha ...          \\n18/10\\n   \n",
       "3                   \\nAtem  chorégraphie Josef Nadj\\n  \\n20/11 → 24/11\\n   \n",
       "4   \\nCantatas  chorégraphie Raimund Hoghe concept...          \\n16/12\\n   \n",
       "5   \\n(M)imosa  conception Cecilia Bengolea…\\n\\n  ...  \\n31/01 → 01/02\\n   \n",
       "6          \\nBaron Samedi  conception Alain Buffard\\n          \\n13/02\\n   \n",
       "7   \\nLe Tsar Saltan musique Nikolaï Rimski-Korsak...          \\n06/04\\n   \n",
       "8   \\nChez Joséphine  chorégraphie Raphaëlle Delau...          \\n16/04\\n   \n",
       "9           \\nRotkäppchen  chorégraphie Sylvain Huc\\n          \\n23/04\\n   \n",
       "10                                                                         \n",
       "11                               \\nEast Block Party\\n                      \n",
       "12  \\nNow the field is open  chorégraphie Hooman S...          \\n15/05\\n   \n",
       "13  \\nPromenade obligatoire  chorégraphie Anne Ngu...          \\n17/05\\n   \n",
       "14   \\nÉtats des lieux  chorégraphie Aurélie Gandit\\n  \\n14/06 → 15/06\\n   \n",
       "\n",
       "             occurency                        place  \n",
       "0                                                    \n",
       "1   [1 rep. + 2 scol.]  \\n (Salle de l'Esplanade)\\n  \n",
       "2             [1 rep.]          \\n (Grande salle)\\n  \n",
       "3             [5 rep.]  \\n (Studio du Gouverneur)\\n  \n",
       "4             [1 rep.]          \\n (Grande salle)\\n  \n",
       "5             [2 rep.]  \\n (Studio du Gouverneur)\\n  \n",
       "6             [1 rep.]          \\n (Grande salle)\\n  \n",
       "7             [1 rep.]                           \\n  \n",
       "8             [1 rep.]          \\n (Grande salle)\\n  \n",
       "9             [1 rep.]      \\n”  (Grande salle)\\n\\n  \n",
       "10                                                   \n",
       "11                                                   \n",
       "12            [1 rep.]          \\n (Grande salle)\\n  \n",
       "13            [1 rep.]      \\n”  (Grande salle)\\n\\n  \n",
       "14            [5 rep.]          \\n (Grande salle)\\n  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#request the url with id of the organism\n",
    "#Example \n",
    "# https://www.lesarchivesduspectacle.net/?IDX_Organisme=439&Saison=2008\n",
    "# Arsenal id 439\n",
    "# import the library we use to open URLs\n",
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "organism=\"439\"\n",
    "saison=\"2013\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\" + organism + \"&Saison=\" + saison\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "#the div where the information is\n",
    "div_interested = soup.find('div', id='async-org-saison-annee')\n",
    "table = div_interested.find_all('table')[0] # Grab the first table \n",
    "df = pd.DataFrame(columns=['organism_id', 'year', 'performance', \n",
    "                           'performanceId', 'author', 'authordId', 'label', 'period', 'occurency','place'])\n",
    "row_marker = 0\n",
    "period=\"\"\n",
    "occurency=\"\"\n",
    "place=\"\"\n",
    "label=\"\"\n",
    "performance=\"\"\n",
    "performanceId=\"\"\n",
    "author=\"\"\n",
    "authorId=\"\"\n",
    "for row in table.find_all('tr'):\n",
    "    column_marker = 0\n",
    "    columns = row.find_all('td')\n",
    "    for column in columns:\n",
    "        organism_id  = organism\n",
    "        year = saison\n",
    "        if(column_marker == 0):\n",
    "            label = columns[0].get_text()\n",
    "            #parse the first td performance - performanceId \n",
    "            performance_element = columns[0].find('a',class_='c_Spectacle')\n",
    "            if(performance_element):\n",
    "                performance = performance_element.contents[0]\n",
    "                performanceId = performance_element['href'].replace(\"/?IDX_Spectacle=\",\"\")\n",
    "                #parse the first td author - authorId\n",
    "            author_element = columns[0].find('a',class_='c_Personne')\n",
    "            if(author_element):\n",
    "                author = author_element.contents[0]\n",
    "                authorId = author_element['href'].replace(\"/?IDX_Personne=\",\"\")\n",
    "        else:\n",
    "            if(column_marker == 1):\n",
    "                period = columns[1].get_text()\n",
    "            if(column_marker == 2):\n",
    "                occurency = columns[2].get_text()       \n",
    "            if(column_marker == 3):\n",
    "                place= columns[3].get_text()\n",
    "        column_marker += 1\n",
    "    df = df.append({'organism_id': organism_id, 'year': year, 'performance': performance,'performanceId': performanceId,'author' : author, 'authordId':  authorId, 'label': label, 'period': period, 'occurency':occurency,'place':place}, ignore_index=True) # yuck         \n",
    "    period=\"\"\n",
    "    occurency=\"\"\n",
    "    place=\"\"\n",
    "    label=\"\"\n",
    "    performance=\"\"\n",
    "    performanceId=\"\"\n",
    "    author=\"\"\n",
    "    authorId=\"\"\n",
    "    row_marker += 1\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request the url with id of the film\n",
    "#Example \n",
    "# http://earlycinema.dch.phil-fak.uni-koeln.de/films/view/1\n",
    "# import the library we use to open URLs\n",
    "import urllib.request\n",
    "import re\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def import_df_performance(organismId,saison):\n",
    "    # specify which URL/web page we are going to be scraping\n",
    "    url = \"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\" + organismId + \"&Saison=\" + saison\n",
    "    # open the url using urllib.request and put the HTML into the page variable\n",
    "    #catch exception some case id doesn't exist cf 970\n",
    "    try:\n",
    "        # open the url using urllib.request and put the HTML into the page variable\n",
    "        page = urllib.request.urlopen(url)\n",
    "        # parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "        #the div where the information is\n",
    "        div_interested = soup.find('div', id='async-org-saison-annee')\n",
    "        table = div_interested.find_all('table')[0] # Grab the first table \n",
    "        df = pd.DataFrame(columns=['organism_id', 'year', 'performance', \n",
    "                           'performanceId', 'author', 'authordId', 'label', 'period', 'occurency','place'])\n",
    "        row_marker = 0\n",
    "        period=\"\"\n",
    "        occurency=\"\"\n",
    "        place=\"\"\n",
    "        label=\"\"\n",
    "        performance=\"\"\n",
    "        performanceId=0\n",
    "        author=\"\"\n",
    "        authorId=0\n",
    "        for row in table.find_all('tr'):\n",
    "            column_marker = 0\n",
    "            columns = row.find_all('td')\n",
    "            for column in columns:\n",
    "                organism_id  = organismId\n",
    "                year = saison\n",
    "                if(column_marker == 0):\n",
    "                    label = columns[0].get_text()\n",
    "                    #parse the first td performance - performanceId \n",
    "                    performance_element = columns[0].find('a',class_='c_Spectacle')\n",
    "                    if(performance_element):\n",
    "                        performance = performance_element.contents[0]\n",
    "                        performanceId = int(performance_element['href'].replace(\"/?IDX_Spectacle=\",\"\"))\n",
    "                        #parse the first td author - authorId\n",
    "                    author_element = columns[0].find('a',class_='c_Personne')\n",
    "                    if(author_element):\n",
    "                        author = author_element.contents[0]\n",
    "                        authorId = int(author_element['href'].replace(\"/?IDX_Personne=\",\"\"))\n",
    "                else:\n",
    "                    if(column_marker == 1):\n",
    "                        period = columns[1].get_text()\n",
    "                    if(column_marker == 2):\n",
    "                        occurency = columns[2].get_text()       \n",
    "                    if(column_marker == 3):\n",
    "                        place= columns[3].get_text()\n",
    "                column_marker += 1\n",
    "            df = df.append({'organism_id': organism_id, 'year': year, 'performance': performance,'performanceId': performanceId,'author' : author, 'authordId':  authorId, 'label': label, 'period': period, 'occurency':occurency,'place':place}, ignore_index=True) # yuck         \n",
    "            period=\"\"\n",
    "            occurency=\"\"\n",
    "            place=\"\"\n",
    "            label=\"\"\n",
    "            performance=\"\"\n",
    "            performanceId=0\n",
    "            author=\"\"\n",
    "            authorId=0\n",
    "            row_marker += 1\n",
    "        return df\n",
    "    except urllib.error.URLError as e:\n",
    "        print(e.reason + \"for organismId \"  + organismId + \" saison \" + saison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2020-07-14 17:19:54.165634\n",
      "invalid literal for int() with base 10: ''\n",
      "invalid literal for int() with base 10: ''\n",
      "finish 2020-07-14 17:20:03.746739\n"
     ]
    }
   ],
   "source": [
    "#call the function\n",
    "import time\n",
    "from datetime import datetime\n",
    "df = pd.DataFrame(columns=['organism_id', 'year', 'performance', 'performanceId', 'author', 'authordId', 'label', 'period', 'occurency','place'])                        \n",
    "print(\"start\",datetime.now()) \n",
    "# 439 Arsenal\n",
    "organismId=\"465\"\n",
    "# 1744 Pôle sud\n",
    "# 465 Le Manège de Reims\n",
    "# 1914 Carreau forbach  \n",
    "# 383 Grand théâtre du Luxembourg \n",
    "for saison in range(2010,2020):\n",
    "    try:\n",
    "        df=df.append(import_df_performance(organismId, str(saison)),sort=False,ignore_index=True)\n",
    "        #df=df.append(import_df_performance(organismId, '2011'),sort=False,ignore_index=True)\n",
    "        #df=df.append(import_df_performance(organismId, '2012'),sort=False,ignore_index=True)\n",
    "        #df=df.append(import_df_performance(organismId, '2013'),sort=False,ignore_index=True)\n",
    "        #df=df.append(import_df_performance(organismId, '2014'),sort=False,ignore_index=True)\n",
    "        #df=df.append(import_df_performance(organismId, '2015'),sort=False,ignore_index=True)\n",
    "        #df=df.append(import_df_performance(organismId, '2016'),sort=False,ignore_index=True)\n",
    "        #df=df.append(import_df_performance(organismId, '2017'),sort=False,ignore_index=True)\n",
    "        #df=df.append(import_df_performance(organismId, '2018'),sort=False,ignore_index=True)\n",
    "        #df=df.append(import_df_performance(organismId, '2019'),sort=False,ignore_index=True)\n",
    "    except (ValueError,IOError) as err:\n",
    "        print(err)\n",
    "    except:\n",
    "        print(\"Problem with organismId %s and saison %s\" % (organismId,str(saison)))\n",
    "        raise\n",
    "df.to_csv('all_10_years_organism_' + organismId + '_convertInt'  '.csv')\n",
    "\n",
    "print(\"finish\",datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fabe50aef156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0mplace\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mcolumn_marker\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'spectacleId'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspectacleId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genre'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'duration'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# yuck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mgenre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genre' is not defined"
     ]
    }
   ],
   "source": [
    "#from a spectacleId retrieve genre and country\n",
    "#spectacleId 22463\n",
    "# import the library we use to open URLs\n",
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "#spectacleId=\"22463\"\n",
    "spectacleId=\"28494\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Spectacle=\" + spectacleId\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "#the div where the information is\n",
    "#the div where the information is\n",
    "div_interested = soup.find('div', class_='fiche__footer')\n",
    "table = div_interested.find_all('table')[0] # Grab the first table   \n",
    "df = pd.DataFrame(columns=['spectacleId','genre', 'duration', 'country'])\n",
    "row_marker = 0\n",
    "for row in table.find_all('tr'):\n",
    "    column_marker = 0\n",
    "    columns = row.find_all('td')\n",
    "    for column in columns:\n",
    "        spectacleId = spectacleId\n",
    "        if(column_marker == 0):\n",
    "            label = columns[0].get_text()\n",
    "            #parse the first td performance - performanceId \n",
    "            performance_element = columns[0].find('a',class_='c_Spectacle')\n",
    "            if(performance_element):\n",
    "                performance = performance_element.contents[0]\n",
    "                performanceId = performance_element['href'].replace(\"/?IDX_Spectacle=\",\"\")\n",
    "                #parse the first td author - authorId\n",
    "            author_element = columns[0].find('a',class_='c_Personne')\n",
    "            if(author_element):\n",
    "                author = author_element.contents[0]\n",
    "                authorId = author_element['href'].replace(\"/?IDX_Personne=\",\"\")\n",
    "            else:\n",
    "                if(column_marker == 1):\n",
    "                    period = columns[1].get_text()\n",
    "                if(column_marker == 2):\n",
    "                    occurency = columns[2].get_text()       \n",
    "                if(column_marker == 3):\n",
    "                    place= columns[3].get_text()\n",
    "            column_marker += 1\n",
    "        df = df.append({'spectacleId': spectacleId, 'genre': genre, 'duration': duration,'country': country}, ignore_index=True) # yuck         \n",
    "        genre=\"\"\n",
    "        duration=\"\"\n",
    "        country=\"\"\n",
    "        row_marker += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table style=\"margin:20px 0 20px 0;\">\n",
      "<tr>\n",
      "<td valign=\"top\">Production\r\n",
      "                </td>\n",
      "<td valign=\"top\">\n",
      "<a class=\"c_Organisme b\" href=\"?IDX_Organisme=2092\">Compagnie Dernière Minute</a><span class=\"em09 n\">  (Toulouse)</span>\n",
      "</td></tr>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "#spectacleId=\"34525\"\n",
    "#spectacleId=\"36956\"\n",
    "spectacleId=\"20185\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Spectacle=\" + spectacleId\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "#the div where the information is\n",
    "#the div where the information is\n",
    "div_interested = soup.find('div', class_='fiche__footer') \n",
    "column_label=[]\n",
    "column_value=[]\n",
    "for row in div_interested.find_all('table')[0].findAll('tr'):\n",
    "    th = row.findAll('th')[0].contents[0]\n",
    "    td = row.findAll('td')[0].contents[0]\n",
    "    column_label.append(th)\n",
    "    column_value.append(td)\n",
    "new_table = pd.DataFrame(columns=column_label, index= [0]) # I know the size\n",
    "for row in div_interested.find_all('table')[0].findAll('tr'):\n",
    "    th = row.findAll('th')[0].contents[0]\n",
    "    td = row.findAll('td')[0].contents[0]\n",
    "    new_table.at[0,th] = td\n",
    "new_table[\"spectacleId\"]=spectacleId\n",
    "#Recuperer creation_date - organism_creation \n",
    "#the div where the information is\n",
    "div_spectacle = soup.find('div', id='div_Spectacle')\n",
    "p_spectacle = div_spectacle.find_all('p')[0]\n",
    "if(p_spectacle):\n",
    "    for time in p_spectacle.findAll('time'):\n",
    "        if time.has_attr('datetime'):\n",
    "            new_table[\"typeDate\"]=time.previousSibling\n",
    "            new_table[\"date\"]=time['datetime']\n",
    "    for organism in p_spectacle.findAll('a',class_ ='c_Organisme'):\n",
    "        if organism.has_attr('href'):\n",
    "            new_table[\"organismeId\"]=organism['href']\n",
    "            new_table[\"organismeName\"]=organism.contents[0].strip()\n",
    "new_table[\"to_analyse\"]=p_spectacle.contents[0].strip()\n",
    "new_table\n",
    "#table[0] class=\"f-spectacle__equipe\"    table[1]  class=\"f-spectacle__equipe\"  \n",
    "table_production = div_spectacle.find_all('table')[2]\n",
    "print(table_production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the div where the information is\n",
    "div_interested = soup.find('div', class_='div_Spectacle') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
