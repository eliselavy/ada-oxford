{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information liée à un spectacle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour un spectacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Durée</th>\n",
       "      <th>Pays</th>\n",
       "      <th>spectacleId</th>\n",
       "      <th>to_analyse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danse</td>\n",
       "      <td>1 heure</td>\n",
       "      <td>France</td>\n",
       "      <td>34525</td>\n",
       "      <td>Création 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre    Durée    Pays  spectacleId     to_analyse\n",
       "0  Danse  1 heure  France        34525  Création 2011"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "spectacleId=\"34525\"\n",
    "#spectacleId=\"36956\"\n",
    "#spectacleId=\"20185\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Spectacle=\" + spectacleId\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "#the div where the information is\n",
    "#the div where the information is\n",
    "div_interested = soup.find('div', class_='fiche__footer') \n",
    "column_label=[]\n",
    "column_value=[]\n",
    "for row in div_interested.find_all('table')[0].findAll('tr'):\n",
    "    th = row.findAll('th')[0].contents[0]\n",
    "    td = row.findAll('td')[0].contents[0]\n",
    "    column_label.append(th)\n",
    "    column_value.append(td)\n",
    "new_table = pd.DataFrame(columns=column_label, index= [0]) # I know the size\n",
    "new_table[\"spectacleId\"]=int(spectacleId)\n",
    "for row in div_interested.find_all('table')[0].findAll('tr'):\n",
    "    th = row.findAll('th')[0].contents[0]\n",
    "    td = row.findAll('td')[0].contents[0].strip()\n",
    "    new_table.at[0,th] = td\n",
    "#Recuperer creation_date - organism_creation \n",
    "#the div where the information is\n",
    "div_spectacle = soup.find('div', id='div_Spectacle')\n",
    "p_spectacle = div_spectacle.find_all('p')[0]\n",
    "if(p_spectacle):\n",
    "    for time in p_spectacle.findAll('time'):\n",
    "        if time.has_attr('datetime'):\n",
    "            new_table[\"typeDate\"]=time.previousSibling\n",
    "            new_table[\"date\"]=time['datetime']\n",
    "    for organism in p_spectacle.findAll('a',class_ ='c_Organisme'):\n",
    "        if organism.has_attr('href'):\n",
    "            new_table[\"organismeId\"]=organism['href']\n",
    "            new_table[\"organismeName\"]=organism.contents[0].strip()\n",
    "new_table[\"to_analyse\"]=p_spectacle.contents[0].strip()\n",
    "#new_table.dtypes\n",
    "#table[0] class=\"f-spectacle__equipe\"    table[1]  class=\"f-spectacle__equipe\"  \n",
    "#table_production = div_spectacle.find_all('table')[2]\n",
    "#print(table_production)\n",
    "new_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction pour récupérer les informations liées à un spectacle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def import_df_type_spectacle(spectacleId):\n",
    "    # specify which URL/web page we are going to be scraping\n",
    "    url = \"https://www.lesarchivesduspectacle.net/?IDX_Spectacle=\" + str(spectacleId)\n",
    "    try:\n",
    "        if spectacleId != 0:\n",
    "            # open the url using urllib.request and put the HTML into the page variable\n",
    "            page = urllib.request.urlopen(url)\n",
    "            # parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "            soup = BeautifulSoup(page, \"lxml\")\n",
    "            div_interested = soup.find('div', class_='fiche__footer') \n",
    "            column_label=[]\n",
    "            column_value=[]\n",
    "            for row in div_interested.find_all('table')[0].findAll('tr'):\n",
    "                th = row.findAll('th')[0].contents[0]\n",
    "                td = row.findAll('td')[0].contents[0]\n",
    "                column_label.append(th)\n",
    "                column_value.append(td)\n",
    "            new_table = pd.DataFrame(columns=column_label, index= [0]) # I know the size\n",
    "            new_table[\"spectacleId\"]=int(spectacleId)\n",
    "            for row in div_interested.find_all('table')[0].findAll('tr'):\n",
    "                th = row.findAll('th')[0].contents[0]\n",
    "                td = row.findAll('td')[0].contents[0].strip()\n",
    "                new_table.at[0,th] = td\n",
    "            #Recuperer creation_date - organism_creation \n",
    "            #the div where the information is\n",
    "            div_spectacle = soup.find('div', id='div_Spectacle')\n",
    "            p_spectacle = div_spectacle.find_all('p')[0]\n",
    "            if(p_spectacle):\n",
    "                for time in p_spectacle.findAll('time'):\n",
    "                    if time.has_attr('datetime'):\n",
    "                        new_table[\"typeDate\"]=time.previousSibling\n",
    "                        new_table[\"date\"]=time['datetime']\n",
    "                for organism in p_spectacle.findAll('a',class_ ='c_Organisme'):\n",
    "                    if organism.has_attr('href'):\n",
    "                        new_table[\"organismeId\"]=organism['href']\n",
    "                        new_table[\"organismeName\"]=organism.contents[0].strip()\n",
    "            new_table[\"to_analyse\"]=p_spectacle.contents[0].strip()\n",
    "            return new_table\n",
    "    except urllib.error.URLError as e:\n",
    "        print(e.reason + \"for spectacleId \"  + str(spectacleId))\n",
    "    except socket.timeout as e: # <-------- this block here\n",
    "        print(\"We timed out\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2020-07-31 15:20:54.119768\n",
      "finish 2020-07-31 15:22:32.146880\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "organismId=\"439\"\n",
    "print(\"start\",datetime.now()) \n",
    "csv_file_path = \"all_10_years_organism_439.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "t_array = df[\"performanceId\"].to_numpy()\n",
    "\n",
    "frames = [ import_df_type_spectacle(f) for f in t_array ]\n",
    "result = pd.concat(frames)\n",
    "result.set_index(['spectacleId'], drop=True, inplace=True)\n",
    "result.to_csv('all_10_years_organism_' + organismId + '_type_spectacle.csv')\n",
    "\n",
    "\n",
    "print(\"finish\",datetime.now())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-27bda442fda5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spectacleId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "list_spectacleId=[\"0\",\"20185\",\"29600\",\"36360\"] \n",
    "list_df=[]\n",
    "for spectacleId in list_spectacleId:\n",
    "    if (spectacleId!=0):\n",
    "        #call the function to have the type_aide and orgnaism\n",
    "        try:\n",
    "            #df_result=import_df_type_spectacle(spectacleId)\n",
    "            df_one=import_df_type_spectacle(spectacleId)\n",
    "            list_df=list_df.append(df_one)\n",
    "        except Exception as err:\n",
    "            continue\n",
    "result = pd.concat(list_df)\n",
    "result.set_index(['spectacleId'], drop=True, inplace=True)\n",
    "result.to_csv('all_10_years_organism_' + organismId + '_type_spectacle.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Durée</th>\n",
       "      <th>Pays</th>\n",
       "      <th>to_analyse</th>\n",
       "      <th>typeDate</th>\n",
       "      <th>date</th>\n",
       "      <th>organismeId</th>\n",
       "      <th>organismeName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectacleId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34525</th>\n",
       "      <td>Danse</td>\n",
       "      <td>1 heure</td>\n",
       "      <td>France</td>\n",
       "      <td>Création 2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20185</th>\n",
       "      <td>Danse – à partir de 7 ans</td>\n",
       "      <td>1 heure</td>\n",
       "      <td>France</td>\n",
       "      <td>Création le</td>\n",
       "      <td>Création le</td>\n",
       "      <td>2009-11-03</td>\n",
       "      <td>?IDX_Organisme=837&amp;Saison=2009</td>\n",
       "      <td>Maison de la Danse de Lyon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29600</th>\n",
       "      <td>Danse</td>\n",
       "      <td>1 heure 15</td>\n",
       "      <td>France</td>\n",
       "      <td>Création le</td>\n",
       "      <td>Création le</td>\n",
       "      <td>2010-08-26</td>\n",
       "      <td>?IDX_Organisme=18808&amp;Annee=2010</td>\n",
       "      <td>Festival d'opéra de Vérone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36360</th>\n",
       "      <td>Théâtre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pologne</td>\n",
       "      <td>Création le</td>\n",
       "      <td>Création le</td>\n",
       "      <td>2011-10-05</td>\n",
       "      <td>?IDX_Organisme=824&amp;Saison=2011</td>\n",
       "      <td>Le Manège</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Genre       Durée     Pays     to_analyse  \\\n",
       "spectacleId                                                                  \n",
       "34525                            Danse     1 heure   France  Création 2011   \n",
       "20185        Danse – à partir de 7 ans     1 heure   France    Création le   \n",
       "29600                            Danse  1 heure 15   France    Création le   \n",
       "36360                          Théâtre         NaN  Pologne    Création le   \n",
       "\n",
       "                 typeDate        date                      organismeId  \\\n",
       "spectacleId                                                              \n",
       "34525                 NaN         NaN                              NaN   \n",
       "20185        Création le   2009-11-03   ?IDX_Organisme=837&Saison=2009   \n",
       "29600        Création le   2010-08-26  ?IDX_Organisme=18808&Annee=2010   \n",
       "36360        Création le   2011-10-05   ?IDX_Organisme=824&Saison=2011   \n",
       "\n",
       "                          organismeName  \n",
       "spectacleId                              \n",
       "34525                               NaN  \n",
       "20185        Maison de la Danse de Lyon  \n",
       "29600        Festival d'opéra de Vérone  \n",
       "36360                         Le Manège  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "list_spectacleId=[\"34525\",\"20185\",\"29600\",\"36360\"] \n",
    "frames = [ import_df_type_spectacle(f) for f in list_spectacleId ]\n",
    "result = pd.concat(frames)\n",
    "result.set_index(['spectacleId'], drop=True, inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
