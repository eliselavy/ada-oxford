{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nPacifique  chorégraphie Nasser Martin-Gousset\\n</td>\n",
       "      <td>\\n09/06\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n (Grande salle)\\n</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0          1         2  \\\n",
       "0  \\nPacifique  chorégraphie Nasser Martin-Gousset\\n  \\n09/06\\n  [1 rep.]   \n",
       "\n",
       "                     3 4  \n",
       "0  \\n (Grande salle)\\n    "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#request the url with id of the organism\n",
    "#Example \n",
    "# https://www.lesarchivesduspectacle.net/?IDX_Organisme=439&Saison=2008\n",
    "# Arsenal id 439\n",
    "# import the library we use to open URLs\n",
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "id=\"439\"\n",
    "saison=\"2010\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\" + id + \"&Saison=\" + saison\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "#the div where the information is\n",
    "div_interested = soup.find('div', id='async-org-saison-annee')\n",
    "table = div_interested.find_all('table')[0] # Grab the first table    \n",
    "new_table = pd.DataFrame(columns=range(0,5), index= [0]) # I know the size\n",
    "row_marker = 0\n",
    "for row in table.find_all('tr'):\n",
    "    column_marker = 0\n",
    "    columns = row.find_all('td')\n",
    "    for column in columns:\n",
    "        new_table.iat[row_marker,column_marker] = column.get_text()\n",
    "        column_marker += 1\n",
    "      \n",
    " \n",
    "new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td>\n",
       "<a class=\"c_Spectacle\" href=\"/?IDX_Spectacle=23453\">Babel (Words)</a>  chorégraphie <a class=\"c_Personne\" href=\"/?IDX_Personne=4676\">Sidi Larbi Cherkaoui</a>…\n",
       "\n",
       "                           </td>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #request the url with id of the organism\n",
    "#Example \n",
    "# https://www.lesarchivesduspectacle.net/?IDX_Organisme=439&Saison=2008\n",
    "# Arsenal id 439\n",
    "# import the library we use to open URLs\n",
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "id=\"439\"\n",
    "saison=\"2010\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\" + id + \"&Saison=\" + saison\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "#the div where the information is\n",
    "div_interested = soup.find('div', id='async-org-saison-annee')\n",
    "table = div_interested.find_all('table')[0] # Grab the first table \n",
    "n_columns = 0\n",
    "n_rows=0\n",
    "column_names = []   \n",
    "rowNumber = [] \n",
    "columnNumber = []\n",
    "content = []\n",
    "# Find number of rows and columns\n",
    "for row in table.find_all('tr'):                \n",
    "    # Determine the number of rows in the table\n",
    "    td_tags = row.find_all('td')\n",
    "    if len(td_tags) > 0:\n",
    "        n_rows+=1\n",
    "        if n_columns == 0:\n",
    "            # Set the number of columns for our table\n",
    "            n_columns = len(td_tags)\n",
    "            \n",
    "df = pd.DataFrame(columns = range(0,n_columns),index= range(0,n_rows))\n",
    "row_marker = 0\n",
    "for row in table.find_all('tr'):\n",
    "    column_marker = 0\n",
    "    columns = row.find_all('td')\n",
    "    for column in columns:\n",
    "        d = {}\n",
    "        if tag.get(\"class\"):\n",
    "            d[tag.get(\"class\")[0]] = [text.strip() for text in tag.findAll(text=True)]\n",
    "        df.iat[row_marker,column_marker] = column\n",
    "        column_marker += 1\n",
    "       \n",
    "    row_marker += 1                \n",
    "        # Convert to float if possible\n",
    "        #for col in df:\n",
    "        #   try:\n",
    "        #        df[col] = df[col].astype(float)\n",
    "        #   except ValueError:\n",
    "        #       pass           \n",
    "df.iat[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>period</th>\n",
       "      <th>occurency</th>\n",
       "      <th>place</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nBabel (Words)  chorégraphie Sidi Larbi Cherk...</td>\n",
       "      <td>\\n08/10 → 09/10\\n</td>\n",
       "      <td>[2 rep.]</td>\n",
       "      <td>\\n (Grande salle)\\n</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nPour l'amour de Cosette d'après Victor Hugo ...</td>\n",
       "      <td>\\n29/10 → 30/10\\n</td>\n",
       "      <td>[2 rep.]</td>\n",
       "      <td>\\n”  (Grande salle)\\n\\n</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nNearly 90²  chorégraphie Merce Cunningham\\n</td>\n",
       "      <td>\\n20/11\\n</td>\n",
       "      <td>[1 rep.]</td>\n",
       "      <td>\\n”  (Grande salle)\\n\\n</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               event             period  \\\n",
       "0  \\nBabel (Words)  chorégraphie Sidi Larbi Cherk...  \\n08/10 → 09/10\\n   \n",
       "1  \\nPour l'amour de Cosette d'après Victor Hugo ...  \\n29/10 → 30/10\\n   \n",
       "2      \\nNearly 90²  chorégraphie Merce Cunningham\\n          \\n20/11\\n   \n",
       "\n",
       "  occurency                    place other  \n",
       "0  [2 rep.]      \\n (Grande salle)\\n        \n",
       "1  [2 rep.]  \\n”  (Grande salle)\\n\\n        \n",
       "2  [1 rep.]  \\n”  (Grande salle)\\n\\n        "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "df.columns = ['event','period','occurency','place','other']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   event      19 non-null     object\n",
      " 1   period     18 non-null     object\n",
      " 2   occurency  17 non-null     object\n",
      " 3   place      17 non-null     object\n",
      " 4   other      17 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 888.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babel (Words)',\n",
       " \"Pour l'amour de Cosette\",\n",
       " 'Nearly 90²',\n",
       " 'LOL',\n",
       " 'Asphalte',\n",
       " 'Zaïna',\n",
       " 'Cribles/Live',\n",
       " \"L'Île solaire\",\n",
       " \"L'Ombre double\",\n",
       " 'Chouf Ouchouf',\n",
       " 'Ismène',\n",
       " '(Sacrées) sorcières !',\n",
       " 'Parades and Changes, replay in expansion',\n",
       " 'Déva-Kitatom',\n",
       " 'Savanna',\n",
       " 'Madame Plaza',\n",
       " 'Pacifique']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "id=\"439\"\n",
    "saison=\"2010\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\" + id + \"&Saison=\" + saison\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "#the div where the information is\n",
    "div_interested = soup.find('div', id='async-org-saison-annee')\n",
    "table = div_interested.find_all('table')[0] # Grab the first table \n",
    "idSpectacles= []\n",
    "nameSpectacles = []\n",
    "for tag in table.find_all('a',class_='c_Spectacle' ):\n",
    "    idSpectacles.append(tag['href'])\n",
    "    nameSpectacles.append(tag.contents[0])\n",
    "for tag in table.find_all('a',class_='c_Spectacle' ):\n",
    "\n",
    "\n",
    " #div_interested.find('a', class_='c_Spectacle').contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowNumber</th>\n",
       "      <th>columnNumber</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nMachinations de François Regnault… mise en s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n02/10\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1 rep.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>\\n (Grande salle)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nAccords  conception Thomas Hauert\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n30/04\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1 rep.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>\\n”  (Grande salle)\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rowNumber  columnNumber                                            content\n",
       "0           0             0  \\nMachinations de François Regnault… mise en s...\n",
       "1           0             1                                          \\n02/10\\n\n",
       "2           0             2                                           [1 rep.]\n",
       "3           0             3                                \\n (Grande salle)\\n\n",
       "4           0             4                                                   \n",
       "..        ...           ...                                                ...\n",
       "60          0             0              \\nAccords  conception Thomas Hauert\\n\n",
       "61          0             1                                          \\n30/04\\n\n",
       "62          0             2                                           [1 rep.]\n",
       "63          0             3                            \\n”  (Grande salle)\\n\\n\n",
       "64          0             4                                                   \n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(rowNumber,columns=['rowNumber'])\n",
    "df['columnNumber']=columnNumber\n",
    "df['content']=content \n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 1, 1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import re\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "id=\"439\"\n",
    "saison=\"2010\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\" + id + \"&Saison=\" + saison\n",
    "#Create a handle, page, to handle the contents of the website\n",
    "page = requests.get(url)\n",
    "#Store the contents of the website under doc\n",
    "doc = lh.fromstring(page.content)\n",
    "#Parse data that are stored between <tr>..</tr> of HTML\n",
    "tr_elements = doc.xpath('//tr')\n",
    "#Check the length of the first 12 rows\n",
    "[len(T) for T in tr_elements[:30]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "id=\"439\"\n",
    "saison=\"2009\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\" + id + \"&Saison=\" + saison\n",
    "\n",
    "dfs = pd.read_html('url')\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error/42334357#42334357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#request the url with id of the organism\n",
    "#Example \n",
    "# https://www.lesarchivesduspectacle.net/?IDX_Organisme=439&Saison=2008\n",
    "# Arsenal id 439\n",
    "# import the library we use to open URLs\n",
    "import urllib.request\n",
    "import re\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "id=\"439\"\n",
    "saison=\"2010\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\" + id + \"&Saison=\" + saison\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "soup\n",
    "#the div where the information is\n",
    "div_interested = soup.find('div', id='async-org-saison-annee')\n",
    "##performance name\n",
    "performance = div_interested.find('a', class_='c_Spectacle').contents[0]\n",
    "##choregraphe\n",
    "choregraphe = div_interested.find('a', class_='c_Personne').contents[0]\n",
    "\n",
    "performances= []\n",
    "choregraphes= []\n",
    "performances.append(performance);\n",
    "choregraphes.append(choregraphe);\n",
    "\n",
    "\n",
    "choregraphes\n",
    "\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-199525b75539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mid\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"&Saison=\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msaison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m         \u001b[0mdisplayed_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m     )\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m             \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \"\"\"\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse_tables\u001b[0;34m(self, doc, match, attrs)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No tables found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error/42334357#42334357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Babel (Words)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#request the url with id of the organism\n",
    "#Example \n",
    "# https://www.lesarchivesduspectacle.net/?IDX_Organisme=439&Saison=2008\n",
    "# Arsenal id 439\n",
    "# import the library we use to open URLs\n",
    "import urllib.request\n",
    "import re\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "id=\"439\"\n",
    "saison=\"2010\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Organisme=\" + id + \"&Saison=\" + saison\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "soup\n",
    "#the div where the information is\n",
    "div_interested = soup.find('div', id='async-org-saison-annee')\n",
    "##performance name\n",
    "performance = div_interested.find('a', class_='c_Spectacle').contents[0]\n",
    "##choregraphe\n",
    "choregraphe = div_interested.find('a', class_='c_Personne').contents[0]\n",
    "\n",
    "performances= []\n",
    "choregraphes= []\n",
    "performances.append(performance);\n",
    "choregraphes.append(choregraphe);\n",
    "\n",
    "\n",
    "performance\n",
    "\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titre</th>\n",
       "      <th>Chorégraphe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babel (Words)</td>\n",
       "      <td>Sidi Larbi Cherkaoui</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Titre           Chorégraphe\n",
       "0  Babel (Words)  Sidi Larbi Cherkaoui"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(performances,columns=['Titre'])\n",
    "df['Chorégraphe']=choregraphes\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
