{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>performanceId</th>\n",
       "      <th>type_aide</th>\n",
       "      <th>organism</th>\n",
       "      <th>organismId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36956</td>\n",
       "      <td>Coproduction</td>\n",
       "      <td>Théâtre National de Chaillot  (Paris)</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36956</td>\n",
       "      <td>Coproduction</td>\n",
       "      <td>HAU Theater Hebbel am Ufer  (Berlin)</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36956</td>\n",
       "      <td>Coproduction</td>\n",
       "      <td>Grand Théâtre de la Ville de Luxembourg  (Luxe...</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36956</td>\n",
       "      <td>Coproduction</td>\n",
       "      <td>La Rose des Vents  (Villeneuve-d'Ascq)</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36956</td>\n",
       "      <td>Coproduction</td>\n",
       "      <td>Centro Cultural Vila Flor  (Guimarães)</td>\n",
       "      <td>12754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36956</td>\n",
       "      <td>Diffusion</td>\n",
       "      <td>Frans Brood Productions  (Gand)</td>\n",
       "      <td>4312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  performanceId     type_aide  \\\n",
       "0         36956  Coproduction   \n",
       "1         36956  Coproduction   \n",
       "2         36956  Coproduction   \n",
       "3         36956  Coproduction   \n",
       "4         36956  Coproduction   \n",
       "5         36956     Diffusion   \n",
       "\n",
       "                                            organism organismId  \n",
       "0              Théâtre National de Chaillot  (Paris)        585  \n",
       "1               HAU Theater Hebbel am Ufer  (Berlin)        206  \n",
       "2  Grand Théâtre de la Ville de Luxembourg  (Luxe...        383  \n",
       "3             La Rose des Vents  (Villeneuve-d'Ascq)        141  \n",
       "4             Centro Cultural Vila Flor  (Guimarães)      12754  \n",
       "5                    Frans Brood Productions  (Gand)       4312  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pour un spectacle voir les coproductions\n",
    "#https://www.lesarchivesduspectacle.net/?IDX_Spectacle=90517#spectacle-partenaires-de-production\n",
    "#Perchée dans les arbres 8 coproductions \n",
    "\n",
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "#spectacleId=\"34525\"\n",
    "spectacleId=\"36956\"\n",
    "#spectacleId=\"90517\"\n",
    "# specify which URL/web page we are going to be scraping\n",
    "url = \"https://www.lesarchivesduspectacle.net/?IDX_Spectacle=\" + spectacleId +\"#spectacle-partenaires-de-production\"\n",
    "# open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(url)\n",
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "#the div where the information is\n",
    "#the div where the information is\n",
    "table = soup.find('table', class_='f-spectacle__production-bis') \n",
    "# Down below we'll add our inmates to this list\n",
    "inmates_list = []\n",
    "\n",
    "# BeautifulSoup provides nice ways to access the data in the parsed\n",
    "# page. Here, we'll use the select method and pass it a CSS style\n",
    "# selector to grab all the rows in the table (the rows contain the \n",
    "# inmate names and ages).\n",
    "\n",
    "for table_row in table.find_all('tr'):\n",
    "    # Each tr (table row) has three td HTML elements (most people \n",
    "    # call these table cels) in it (first name, last name, and age)\n",
    "    cells = table_row.findAll('td')\n",
    "    # Our table has one exception -- a row without any cells.\n",
    "    # Let's handle that special case here by making sure we\n",
    "    # have more than zero cells before processing the cells\n",
    "    if len(cells) > 0:\n",
    "        organism = cells[1].text.strip()\n",
    "        organism_element = cells[1].find('a',class_='c_Organisme b')\n",
    "        organismId = organism_element['href'].replace(\"?IDX_Organisme=\",\"\")\n",
    "        type_aide = cells[0].text.strip()\n",
    "        if(type_aide != ''):\n",
    "            type_aide_master = type_aide\n",
    "        \n",
    "        else:\n",
    "            type_aide = type_aide_master\n",
    "        inmate = {'performanceId': spectacleId,'type_aide': type_aide,'organism': organism,'organismId': organismId}\n",
    "        inmates_list.append(inmate)\n",
    "\n",
    "df = pd.DataFrame(inmates_list)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function return dataframe with type_aide and organism\n",
    "import urllib.request\n",
    "import re\n",
    "# import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def import_df_type_production(spectacleId,saison):\n",
    "    # specify which URL/web page we are going to be scraping\n",
    "    url = \"https://www.lesarchivesduspectacle.net/?IDX_Spectacle=\" + spectacleId +\"#spectacle-partenaires-de-production\"\n",
    "    try:\n",
    "        page = urllib.request.urlopen(url)\n",
    "        # parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "        soup = BeautifulSoup(page, \"lxml\")\n",
    "        table = soup.find('table', class_='f-spectacle__production-bis') \n",
    "        # Down below we'll add our inmates to this list\n",
    "        inmates_list = []\n",
    "        for table_row in table.find_all('tr'):\n",
    "            cells = table_row.findAll('td')\n",
    "            if len(cells) > 0:\n",
    "                organism = cells[1].text.strip()\n",
    "                organism_element = cells[1].find('a',class_='c_Organisme b')\n",
    "                organismId = organism_element['href'].replace(\"?IDX_Organisme=\",\"\")\n",
    "                type_aide = cells[0].text.strip()\n",
    "                if(type_aide != ''):\n",
    "                    type_aide_master = type_aide \n",
    "                else:\n",
    "                    type_aide = type_aide_master\n",
    "                inmate = {'performanceId': spectacleId,'type_aide': type_aide,'organism': organism,'organismId': organismId,'saison':saison}\n",
    "                inmates_list.append(inmate)\n",
    "\n",
    "        df = pd.DataFrame(inmates_list)\n",
    "        return df\n",
    "    except urllib.error.URLError as e:\n",
    "        print(e.reason + \"for spectacleId \"  + spectacleId + \" saison \" + saison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        int64\n",
       "organism_id       int64\n",
       "year              int64\n",
       "performance      object\n",
       "performanceId     int64\n",
       "author           object\n",
       "authordId         int64\n",
       "label            object\n",
       "period           object\n",
       "occurency        object\n",
       "place            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2020-07-25 21:52:50.235914\n",
      "Problem with organismId 439\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-220ff20fe957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#call the function to have the type_aide and orgnaism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_df_type_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformanceId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-02a9d637acb5>\u001b[0m in \u001b[0;36mimport_df_type_production\u001b[0;34m(spectacleId, saison)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Down below we'll add our inmates to this list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0minmates_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtable_row\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mcells\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "#Pour les spectacles à l'Arsenal voir les types d'aide\n",
    "# ORGANISM ID DE L'ETUDE\n",
    "# 439 Arsenal\n",
    "# 699 CCAM [Centre culturel André Malraux] - Scène Nationale de Vandoeuvre-lès-Nancy\n",
    "# 383 Grand théâtre du Luxembourg\n",
    "# 1914 Carreau forbach \n",
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "organismId=\"439\"\n",
    "csv_file_path = \"all_10_years_organism_439.csv\"\n",
    "df_organism = pd.read_csv(csv_file_path)\n",
    "df = pd.DataFrame(columns=['performanceId','type_aide','organism','organismId'])                        \n",
    "print(\"start\",datetime.now()) \n",
    "for row in df_organism.itertuples():\n",
    "    if (row.performanceId!=0):\n",
    "        #call the function to have the type_aide and orgnaism\n",
    "        try:\n",
    "            df=df.append(import_df_type_production(str(row.performanceId),row.year),sort=False,ignore_index=True)\n",
    "        except (ValueError,IOError) as err:\n",
    "            print(err)\n",
    "        except:\n",
    "            print(\"Problem with organismId %s\" % (organismId))\n",
    "            raise\n",
    "df.to_csv('all_10_years_organism_' + organismId + '_type_production.csv')\n",
    "\n",
    "print(\"finish\",datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File all_10_years_organism_439_type_production.csv does not exist: 'all_10_years_organism_439_type_production.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bed63031a141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcsv_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"all_10_years_organism_439_type_production.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_type_production\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_type_production\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_type_production\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_type_production\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type_aide'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Coproduction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File all_10_years_organism_439_type_production.csv does not exist: 'all_10_years_organism_439_type_production.csv'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "csv_file_path = \"all_10_years_organism_439_type_production.csv\"\n",
    "df_type_production = pd.read_csv(csv_file_path)\n",
    "\n",
    "df_type_production = df_type_production[df_type_production['type_aide'] == 'Coproduction']\n",
    "#where coproduction est Arsenal\n",
    "#df_type_production = df_type_production[df_type_production['organismId'] == '439']\n",
    "df_type_production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
